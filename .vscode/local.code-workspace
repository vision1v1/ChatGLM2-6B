{
    "folders": [
        {
            "path": ".."
        }
    ],
    "settings": {
        "python.defaultInterpreterPath": "D:/common_program/miniconda3/envs/me/python.exe",
        "[python]": {
            "editor.defaultFormatter": "ms-python.autopep8",
            "editor.formatOnSave": false
        },
        "editor.minimap.enabled": false,
        "explorer.autoReveal": false,
    },
    "launch": {
        "version": "0.2.0",
        "configurations": [
            {
                "name": "main.py",
                "type": "python",
                "request": "launch",
                "program": "${workspaceFolder}/ptuning/main.py",
                "args": [
                    "--do_train",
                    "--train_file", "AdvertiseGen/train.json",
                    "--validation_file", "AdvertiseGen/dev.json",
                    "--preprocessing_num_workers", "10",
                    "--prompt_column", "content",
                    "--response_column", "summary",
                    "--overwrite_cache",
                    "--model_name_or_path", "C:/data/pretrained/THUDM/chatglm2-6b",
                    "--output_dir", "output/adgen-chatglm2-6b-pt-128-2e-2",
                    "--overwrite_output_dir",
                    "--max_source_length", "64",
                    "--max_target_length", "128",
                    "--per_device_train_batch_size", "1",
                    "--per_device_eval_batch_size", "1",
                    "--gradient_accumulation_steps", "16",
                    "--predict_with_generate",
                    "--max_steps", "3000",
                    "--logging_steps", "10",
                    "--save_steps", "1000",
                    "--learning_rate", "2e-2",
                    "--pre_seq_len", "128", // 预测长度
                    // "--quantization_bit", "4"
                ],
                "cwd": "${workspaceFolder}/ptuning",
                "justMyCode": false
            },
        ],
        "compounds": []
    }
}